{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text\n",
    "from datetime import date, datetime, timedelta\n",
    "from jugaad_data.nse import full_bhavcopy_save, bhavcopy_fo_save, bhavcopy_raw\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "ERROR_TABLE_NAME = \"nse_error_dates\"\n",
    "HISTORY_TABLE = \"Nse_history\"\n",
    "BHAVCOPY_FOLDER = \"nse_bhavcopies\"\n",
    "\n",
    "HOST = \"DESKTOP-0H6SQRG\"\n",
    "DB = \"nse\"\n",
    "DRIVER = \"ODBC+Driver+11+for+SQL+Server\"\n",
    "# conn = create_engine(f'mssql+pyodbc://{HOST}/{DB}?trusted_connection=yes&driver={DRIVER}')\n",
    "\n",
    "\n",
    "CREATE_ERROR_TABLE_QUERY = f\"\"\"IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='{ERROR_TABLE_NAME}' and xtype='U')\n",
    "                                create table {ERROR_TABLE_NAME}(id int primary key identity(1,1), [date] date not null,\n",
    "                                timestamp datetime default current_timestamp)\"\"\"\n",
    "\n",
    "REQUIRED_COLUMNS = [\"Date\", \"Symbol\", \"Series\", \"Prev Close\", \"Open\", \"High\", \"Low\", \"Last\", \"Close\", \"VWAP\",\n",
    "                    \"Volume\", \"Trades\", \"Deliverable Volume\", \"%Deliverble\"]\n",
    "\n",
    "\n",
    "CREATE_HISTORY_TABLE_QUERY = f\"\"\"IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='{HISTORY_TABLE}' and xtype='U')\n",
    "                                CREATE TABLE {HISTORY_TABLE}(\n",
    "                                [id] [bigint] primary key identity(1,1),\n",
    "                                [Date] [date] NULL,\n",
    "                                [Symbol] [varchar](50) NULL,\n",
    "                                [Series] [varchar](50) NULL,\n",
    "                                [Prev Close] [varchar](50) NULL,\n",
    "                                [Open] [varchar](50) NULL,\n",
    "                                [High] [varchar](50) NULL,\n",
    "                                [Low] [varchar](50) NULL,\n",
    "                                [Last] [varchar](50) NULL,\n",
    "                                [Close] [varchar](50) NULL,\n",
    "                                [VWAP] [varchar](50) NULL,\n",
    "                                [Volume] [varchar](50) NULL,\n",
    "                                [Turnover] [varchar](50) NULL,\n",
    "                                [Trades] [varchar](50) NULL,\n",
    "                                [Deliverable Volume] [varchar](50) NULL,\n",
    "                                [%Deliverble] [varchar](50) NULL,\n",
    "                                [timestamp] [datetime] default current_timestamp\n",
    "                            )\"\"\"\n",
    "\n",
    "column_mappings = {\n",
    "    \"date\": \"Date\", \"symbol\": \"Symbol\", \"pclose\": \"Prev Close\", \"open\": \"Open\", \"high\": \"High\", \"low\":\"Low\", \"close\": \"Close\",\n",
    "    \"vwap\": \"VWAP\", \"volume\": \"Volume\", \"trades\": \"Trades\", \"dvolume\": \"Deliverable Volume\", \"pdeliverble\":\"%Deliverble\",\n",
    "    \"series\": \"Series\", \"last\": \"Last\"}\n",
    "\n",
    "\n",
    "# conn = create_engine(\"mssql+pyodbc:///?odbc_connect={}\".format(params))\n",
    "engine = create_engine(f'mssql+pyodbc://{HOST}/{DB}?trusted_connection=yes&driver={DRIVER}')\n",
    "conn = engine.connect()\n",
    "realpath_bhavcopy = os.path.join(os.getcwd(), BHAVCOPY_FOLDER)\n",
    "if not os.path.exists(realpath_bhavcopy):\n",
    "    os.mkdir(realpath_bhavcopy)\n",
    "\n",
    "\n",
    "def execute_sql(query, commit=False):\n",
    "    result = conn.execute(text(query))\n",
    "    if commit:\n",
    "        conn.commit()\n",
    "    return result\n",
    "\n",
    "\n",
    "execute_sql(CREATE_ERROR_TABLE_QUERY, commit=True)\n",
    "execute_sql(CREATE_HISTORY_TABLE_QUERY, commit=True)\n",
    "\n",
    "\n",
    "def if_exists(tablename, date=None, df=None):\n",
    "    DUPLICATE_CHECK_QUERY = \"\"\"select * from {TABLENAME} where {DATE_COL}='{DATE}' \n",
    "                                and {SYMBOL_COL}='{SYMBOL}'\"\"\"\n",
    "    SINGLE_CHECK_QUERY = \"select * from {TABLENAME} where {DATE_COL}='{DATE}'\"\n",
    "    result = None\n",
    "    if date:\n",
    "        result = execute_sql(SINGLE_CHECK_QUERY.format(TABLENAME=tablename, DATE_COL=column_mappings[\"date\"],\n",
    "                                                           DATE=date)).fetchone()\n",
    "        \n",
    "    elif df is not None:\n",
    "        rand_rec = df.sample()\n",
    "        rand_rec = rand_rec.to_dict(\"records\")[0]\n",
    "        result = execute_sql(DUPLICATE_CHECK_QUERY.format(TABLENAME=tablename, \n",
    "                                                           DATE_COL=column_mappings[\"date\"],\n",
    "                                                           SYMBOL_COL=column_mappings[\"symbol\"], \n",
    "                                                           DATE=rand_rec[column_mappings[\"date\"]],\n",
    "                                                           SYMBOL=rand_rec[column_mappings[\"symbol\"]])).fetchone()\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "\n",
    "def convert_strto_datetime(date_time):\n",
    "    try:\n",
    "        datetime_str = datetime.strptime(date_time, '%d-%b-%Y')\n",
    "    except ValueError:\n",
    "        datetime_str = datetime.strptime(date_time, '%d-%m-%Y')\n",
    "    return datetime_str\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df.rename(columns={\" DATE1\": column_mappings[\"date\"], \"SYMBOL\": column_mappings[\"symbol\"],\n",
    "                            \" SERIES\": column_mappings[\"series\"], \" PREV_CLOSE\": column_mappings[\"pclose\"],\n",
    "                            \" OPEN_PRICE\": column_mappings[\"open\"], \" HIGH_PRICE\": column_mappings[\"high\"] , \n",
    "                            \" LOW_PRICE\": column_mappings[\"low\"], \" LAST_PRICE\": column_mappings[\"last\"],\n",
    "                            \" CLOSE_PRICE\": column_mappings[\"close\"], \" AVG_PRICE\": column_mappings[\"vwap\"], \n",
    "                            \" TTL_TRD_QNTY\": column_mappings[\"volume\"], \" NO_OF_TRADES\": column_mappings[\"trades\"],\n",
    "                            \" DELIV_QTY\": column_mappings[\"dvolume\"], \" DELIV_PER\": column_mappings[\"pdeliverble\"]})\n",
    "\n",
    "    df[column_mappings[\"date\"]] = df[column_mappings[\"date\"]].apply(lambda x: x.strip())\n",
    "    df[column_mappings[\"date\"]] = df[column_mappings[\"date\"]].apply(convert_strto_datetime)\n",
    "    df[column_mappings[\"symbol\"]] = df[column_mappings[\"symbol\"]].apply(lambda x: x.strip())\n",
    "    df[column_mappings[\"series\"]] = df[column_mappings[\"series\"]].apply(lambda x: x.strip())\n",
    "\n",
    "    return df[REQUIRED_COLUMNS]\n",
    "\n",
    "def save_bc(dt):\n",
    "    fileloc = full_bhavcopy_save(dt, realpath_bhavcopy)\n",
    "    df = pd.read_csv(fileloc)\n",
    "    df = clean_data(df)\n",
    "    df.to_sql(HISTORY_TABLE, engine, if_exists=\"append\", index=False)\n",
    "    print(f\"Saved data for {dt.strftime('%d-%b-%Y')} day..\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9529f2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d63f26e6",
   "metadata": {},
   "source": [
    "## download data from existing table based on last date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b909693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_date = execute_sql(f\"select top(1){column_mappings['date']} from {HISTORY_TABLE} order by {column_mappings['date']} DESC\").fetchone()\n",
    "print(f\"last date found in database is {getattr(last_date,column_mappings['date']).strftime('%d-%b-%Y')}\")\n",
    "next_date = getattr(last_date,column_mappings['date']\n",
    "yesterday = date.today()-timedelta(days=1)\n",
    "while True:\n",
    "    try:\n",
    "        if yesterday < next_date:\n",
    "            break\n",
    "        next_date = next_date+timedelta(days=1)\n",
    "        str_date = next_date.strftime('%d-%b-%Y')\n",
    "        if next_date.weekday() < 5:\n",
    "#             print(str_date)\n",
    "            try:\n",
    "                if if_exists(HISTORY_TABLE, next_date):\n",
    "                    print(f\"Data already exists for {str_date} in {HISTORY_TABLE} table\")\n",
    "                    continue\n",
    "                df = save_bc(next_date)\n",
    "            except Exception as e:\n",
    "                print(f\"error occured on {str_date} {e}\")\n",
    "                execute_sql(f\"insert into {ERROR_TABLE_NAME}([date]) values('{next_date}')\", commit=True)\n",
    "                continue\n",
    "        time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Download interrupted..\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa158e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "623c7c1b",
   "metadata": {},
   "source": [
    "## Download data for the date in error table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808f6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err_dates = execute_sql(f\"select [date] as {column_mappings['date']} from {ERROR_TABLE_NAME}\").fetchall()\n",
    "for d in err_dates:\n",
    "    try:\n",
    "#         print(d[column_mappings[\"date\"]].strftime('%d-%b-%Y'))\n",
    "        save_bc(getattr(d, column_mappings[\"date\"]))\n",
    "        execute_sql(f\"delete {ERROR_TABLE_NAME} where date='{d[column_mappings['date']]}'\", commit=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656788aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce67742",
   "metadata": {},
   "source": [
    "## Download data for a Single day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6127800",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_date = \"03-01-2022\"                #dd/mm/yyyy\n",
    "\n",
    "dt = convert_strto_datetime(download_date)\n",
    "if dt.weekday() > 4:\n",
    "    print(f\"Sorry its a weekend.. {download_date}\")\n",
    "elif if_exists(HISTORY_TABLE, dt):\n",
    "    print(f\"Data already exists for {download_date} in {HISTORY_TABLE} table\")\n",
    "else:\n",
    "    df = save_bc(dt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b7235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
